{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HlAvkw68u00",
        "outputId": "1a5c2103-4c87-4bba-b525-dcc1ba57afde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=c2a0b065f5d6af87435e7b1e98e81e6f558533bdd0ba5f52750ead20fd039aa8\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install farasa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D91FvJdc81sJ",
        "outputId": "df8b458e-6eb2-4476-b1ad-6bf0b6ef43d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting farasa\n",
            "  Downloading Farasa-0.0.1-py2.py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: farasa\n",
            "Successfully installed farasa-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install farasapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSpum0579BMt",
        "outputId": "34ce211c-24cb-44bb-8079-c47bb786c661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting farasapy\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2023.11.17)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2ZDCNr-_RKS",
        "outputId": "0aa4e2fe-b570-45b0-eea7-bf9c115583d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKIY2lS77e3N",
        "outputId": "e81b8862-b651-4e94-cc6a-be7f0965453b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'farasa-api.qcri.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 241M/241M [03:14<00:00, 1.24MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-12-20 11:37:11,422 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:37:17,114 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:37:21,516 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:37:26,493 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:37:31,652 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:37:36,284 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:37:42,392 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:37:46,887 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:37:51,729 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:37:57,683 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:02,228 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:07,498 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:12,908 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:17,327 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:23,154 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:27,774 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:32,249 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:38,449 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:43,068 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:47,611 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:54,148 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:38:58,752 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:39:04,000 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:39:09,651 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:39:14,396 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 11:42:02,355 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "import spacy\n",
        "from langdetect import detect\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from snowballstemmer import stemmer\n",
        "from farasa.segmenter import FarasaSegmenter\n",
        "\n",
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv('songs.csv')\n",
        "\n",
        "# Fonction pour le nettoyage du texte\n",
        "def preprocess_text(text):\n",
        "    # Tokenisation\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    # Lowercasing\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "\n",
        "    # Suppression des chiffres\n",
        "    tokens = [token for token in tokens if not token.isdigit()]\n",
        "\n",
        "    # Suppression des stop words (anglais)\n",
        "    stop_words_english = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words_english]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Fonction pour le stemming en anglais\n",
        "def apply_stemming_english(tokens):\n",
        "    stemmer_english = SnowballStemmer('english')\n",
        "    stemmed_tokens = [stemmer_english.stem(token) for token in tokens]\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Fonction pour la lemmatisation en anglais\n",
        "def apply_lemmatization_english(text):\n",
        "    nlp_english = spacy.load('en_core_web_sm')\n",
        "    doc_english = nlp_english(text)\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc_english]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Fonction pour le stemming en français\n",
        "def apply_stemming_french(tokens):\n",
        "    stemmer_french = stemmer(\"french\")\n",
        "    stemmed_tokens = stemmer_french.stemWords(tokens)\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Fonction pour la lemmatisation en français\n",
        "def apply_lemmatization_french(text):\n",
        "    nlp_french = spacy.load('fr_core_news_sm')\n",
        "    doc_french = nlp_french(text)\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc_french]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Fonction pour le stemming en arabe\n",
        "def apply_stemming_arabic(text):\n",
        "    segmenter = FarasaSegmenter(interactive=True)\n",
        "    segmented_text = segmenter.segment(text)\n",
        "    return segmented_text.split()\n",
        "\n",
        "# Fonction pour la lemmatisation en arabe\n",
        "def apply_lemmatization_arabic(text):\n",
        "    segmenter = FarasaSegmenter(interactive=True)\n",
        "    segmented_text = segmenter.segment(text)\n",
        "    return segmented_text.split()\n",
        "\n",
        "# Appliquer les étapes de prétraitement par texte et détecter la langue\n",
        "def apply_preprocessing(row):\n",
        "    text = row['Lyrics']\n",
        "    lang = detect(text)\n",
        "\n",
        "    tokens = preprocess_text(text)\n",
        "\n",
        "    if lang == 'en':\n",
        "        row['Lyrics_Stemmed'] = apply_stemming_english(tokens)\n",
        "        row['Lyrics_Lemmatized'] = apply_lemmatization_english(text)\n",
        "    elif lang == 'fr':\n",
        "        row['Lyrics_Stemmed'] = apply_stemming_french(tokens)\n",
        "        row['Lyrics_Lemmatized'] = apply_lemmatization_french(text)\n",
        "    elif lang == 'ar':\n",
        "        row['Lyrics_Stemmed'] = apply_stemming_arabic(text)\n",
        "        row['Lyrics_Lemmatized'] = apply_lemmatization_arabic(text)\n",
        "    else:\n",
        "        row['Lyrics_Stemmed'] = tokens\n",
        "        row['Lyrics_Lemmatized'] = tokens\n",
        "\n",
        "    return row\n",
        "\n",
        "# Appliquer les étapes de prétraitement par ligne\n",
        "df = df.apply(apply_preprocessing, axis=1)\n",
        "\n",
        "# Sauvegarder les résultats dans un nouveau fichier CSV\n",
        "df.to_csv('resultats_pretraites.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv('songs.csv')\n"
      ],
      "metadata": {
        "id": "_QA0dhlj91VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "import spacy\n",
        "from langdetect import detect\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from snowballstemmer import stemmer\n",
        "from farasa.segmenter import FarasaSegmenter\n",
        "\n",
        "# Fonction pour le nettoyage du texte\n",
        "def preprocess_text(text):\n",
        "    # Tokenisation\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    # Lowercasing\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "\n",
        "    # Suppression des chiffres\n",
        "    tokens = [token for token in tokens if not token.isdigit()]\n",
        "\n",
        "    # Suppression des stop words (anglais)\n",
        "    stop_words_english = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words_english]\n",
        "\n",
        "    return tokens\n",
        "# Fonctions pour le stemming et la lemmatisation en anglais, français et arabe\n",
        "\n",
        "# Fonction pour le stemming en anglais\n",
        "def apply_stemming_english(tokens):\n",
        "    stemmer_english = SnowballStemmer('english')\n",
        "    stemmed_tokens = [stemmer_english.stem(token) for token in tokens]\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Fonction pour la lemmatisation en anglais\n",
        "def apply_lemmatization_english(text):\n",
        "    nlp_english = spacy.load('en_core_web_sm')\n",
        "    doc_english = nlp_english(text)\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc_english]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Fonction pour le stemming en français\n",
        "def apply_stemming_french(tokens):\n",
        "    stemmer_french = stemmer(\"french\")\n",
        "    stemmed_tokens = stemmer_french.stemWords(tokens)\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Fonction pour la lemmatisation en français\n",
        "def apply_lemmatization_french(text):\n",
        "    nlp_french = spacy.load('fr_core_news_sm')\n",
        "    doc_french = nlp_french(text)\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc_french]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Fonction pour le stemming en arabe\n",
        "def apply_stemming_arabic(text):\n",
        "    segmenter = FarasaSegmenter(interactive=True)\n",
        "    segmented_text = segmenter.segment(text)\n",
        "    return segmented_text.split()\n",
        "\n",
        "# Fonction pour la lemmatisation en arabe\n",
        "def apply_lemmatization_arabic(text):\n",
        "    segmenter = FarasaSegmenter(interactive=True)\n",
        "    segmented_text = segmenter.segment(text)\n",
        "    return segmented_text.split()\n"
      ],
      "metadata": {
        "id": "eqP9ptom94Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour appliquer le prétraitement par ligne\n",
        "def apply_preprocessing(row):\n",
        "    text = row['Lyrics']\n",
        "    lang = detect(text)\n",
        "\n",
        "    tokens = preprocess_text(text)\n",
        "\n",
        "    if lang == 'en':\n",
        "        row['Lyrics_Stemmed'] = apply_stemming_english(tokens)\n",
        "        row['Lyrics_Lemmatized'] = apply_lemmatization_english(text)\n",
        "    elif lang == 'fr':\n",
        "        row['Lyrics_Stemmed'] = apply_stemming_french(tokens)\n",
        "        row['Lyrics_Lemmatized'] = apply_lemmatization_french(text)\n",
        "    elif lang == 'ar':\n",
        "        row['Lyrics_Stemmed'] = apply_stemming_arabic(text)\n",
        "        row['Lyrics_Lemmatized'] = apply_lemmatization_arabic(text)\n",
        "    else:\n",
        "        row['Lyrics_Stemmed'] = tokens\n",
        "        row['Lyrics_Lemmatized'] = tokens\n",
        "\n",
        "    return row\n"
      ],
      "metadata": {
        "id": "EZ9mAGYX-MTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliquer le prétraitement sur le DataFrame\n",
        "df = df.apply(apply_preprocessing, axis=1)\n",
        "\n",
        "# Sauvegarder les résultats dans un nouveau fichier CSV\n",
        "df.to_csv('resultats_pretraites.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Twg5f62i-SRA",
        "outputId": "59a16f5f-fe82-48ff-f0b7-250c40e18cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'farasa-api.qcri.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 241M/241M [03:23<00:00, 1.18MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-12-20 20:49:12,598 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:15,857 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:19,061 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:22,609 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:26,192 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:29,503 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:32,973 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:36,926 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:40,370 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:43,621 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:47,503 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:50,935 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:54,122 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:49:57,779 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:50:01,405 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:50:04,636 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:50:07,947 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:50:11,996 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:50:15,389 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:50:18,641 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:50:22,599 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:50:25,928 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:50:29,152 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:50:32,624 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:53:02,943 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langdetect import detect\n",
        "from farasa.segmenter import FarasaSegmenter\n",
        "import spacy\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from snowballstemmer import stemmer\n",
        "\n",
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv('songs.csv')\n",
        "\n",
        "# Fonction pour le nettoyage du texte\n",
        "def preprocess_text(text):\n",
        "    # Tokenisation\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    # Lowercasing\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "\n",
        "    # Suppression des chiffres\n",
        "    tokens = [token for token in tokens if not token.isdigit()]\n",
        "\n",
        "    # Suppression des stop words (anglais)\n",
        "    stop_words_english = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words_english]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Fonction pour le stemming en anglais\n",
        "def apply_stemming_english(tokens):\n",
        "    stemmer_english = stemmer(\"english\")\n",
        "    stemmed_tokens = stemmer_english.stemWords(tokens)\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Fonction pour la lemmatisation en anglais\n",
        "def apply_lemmatization_english(text):\n",
        "    nlp_english = spacy.load('en_core_web_sm')\n",
        "    doc_english = nlp_english(text)\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc_english]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Fonction pour le stemming en français\n",
        "def apply_stemming_french(tokens):\n",
        "    stemmer_french = stemmer(\"french\")\n",
        "    stemmed_tokens = stemmer_french.stemWords(tokens)\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Fonction pour la lemmatisation en français\n",
        "def apply_lemmatization_french(text):\n",
        "    nlp_french = spacy.load('fr_core_news_sm')\n",
        "    doc_french = nlp_french(text)\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc_french]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Fonction pour le stemming en arabe\n",
        "def apply_stemming_arabic(text):\n",
        "    segmenter = FarasaSegmenter(interactive=True)\n",
        "    segmented_text = segmenter.segment(text)\n",
        "    return segmented_text.split()\n",
        "\n",
        "# Fonction pour la lemmatisation en arabe\n",
        "def apply_lemmatization_arabic(text):\n",
        "    segmenter = FarasaSegmenter(interactive=True)\n",
        "    segmented_text = segmenter.segment(text)\n",
        "    return segmented_text.split()\n",
        "\n",
        "# Appliquer les étapes de prétraitement par texte et détecter la langue\n",
        "def apply_preprocessing_batch(df_batch):\n",
        "    processed_rows = []\n",
        "\n",
        "    for index, row in df_batch.iterrows():\n",
        "        text = row['Lyrics']\n",
        "        lang = detect(text)\n",
        "\n",
        "        tokens = preprocess_text(text)\n",
        "\n",
        "        if lang == 'en':\n",
        "            stemmed = apply_stemming_english(tokens)\n",
        "            lemmatized = apply_lemmatization_english(text)\n",
        "        elif lang == 'fr':\n",
        "            stemmed = apply_stemming_french(tokens)\n",
        "            lemmatized = apply_lemmatization_french(text)\n",
        "        elif lang == 'ar':\n",
        "            stemmed = apply_stemming_arabic(text)\n",
        "            lemmatized = apply_lemmatization_arabic(text)\n",
        "        else:\n",
        "            stemmed = tokens\n",
        "            lemmatized = tokens\n",
        "\n",
        "        processed_rows.append({\n",
        "            'Lyrics_Stemmed': stemmed,\n",
        "            'Lyrics_Lemmatized': lemmatized\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(processed_rows)\n",
        "\n",
        "# Diviser le DataFrame en lots de taille batch_size et appliquer le prétraitement\n",
        "batch_size = 1000\n",
        "num_batches = len(df) // batch_size + 1\n",
        "processed_dfs = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min((i + 1) * batch_size, len(df))\n",
        "    df_batch = df.iloc[start_idx:end_idx]\n",
        "    processed_df_batch = apply_preprocessing_batch(df_batch)\n",
        "    processed_dfs.append(processed_df_batch)\n",
        "\n",
        "# Concaténer les DataFrames traités en lots\n",
        "final_processed_df = pd.concat(processed_dfs, ignore_index=True)\n",
        "\n",
        "# Sauvegarder les résultats dans un nouveau fichier CSV\n",
        "final_processed_df.to_csv('resultats_pretraites.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JruYU-u3BHO4",
        "outputId": "2d5015ea-5aa9-47a7-80eb-3834497bd581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-12-20 20:58:18,619 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:21,816 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:25,674 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:28,969 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:32,177 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:36,158 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:39,575 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:43,180 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:47,257 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:50,660 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:54,039 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:58:57,653 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:01,743 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:05,211 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:08,729 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:12,818 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:16,218 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:19,463 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:23,473 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:26,688 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:30,035 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:33,352 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:37,564 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:40,994 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 20:59:48,930 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langdetect import detect\n",
        "from farasa.segmenter import FarasaSegmenter\n",
        "import spacy\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from snowballstemmer import stemmer\n",
        "\n",
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv('songs.csv')\n",
        "\n",
        "# Diviser le DataFrame en lots plus petits\n",
        "batch_size = 1000\n",
        "num_batches = len(df) // batch_size + 1\n",
        "processed_dfs = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min((i + 1) * batch_size, len(df))\n",
        "    df_batch = df.iloc[start_idx:end_idx]\n",
        "\n",
        "    processed_rows = []\n",
        "    for index, row in df_batch.iterrows():\n",
        "        text = row['Lyrics']\n",
        "        lang = detect(text)\n",
        "\n",
        "        # Nettoyage du texte\n",
        "        tokenizer = RegexpTokenizer(r'\\w+')\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        tokens = [token.lower() for token in tokens if not token.isdigit()]\n",
        "        stop_words_english = set(stopwords.words('english'))\n",
        "        tokens = [token for token in tokens if token not in stop_words_english]\n",
        "\n",
        "        # Appliquer les opérations linguistiques en fonction de la langue\n",
        "        if lang == 'en':\n",
        "            stemmer_english = stemmer(\"english\")\n",
        "            stemmed_tokens = stemmer_english.stemWords(tokens)\n",
        "            lemmatized_tokens = tokens  # Remplacer par la lemmatisation si nécessaire\n",
        "        elif lang == 'fr':\n",
        "            stemmer_french = stemmer(\"french\")\n",
        "            stemmed_tokens = stemmer_french.stemWords(tokens)\n",
        "            lemmatized_tokens = tokens  # Remplacer par la lemmatisation si nécessaire\n",
        "        elif lang == 'ar':\n",
        "            segmenter = FarasaSegmenter(interactive=True)\n",
        "            segmented_text = segmenter.segment(text)\n",
        "            stemmed_tokens = segmented_text.split()\n",
        "            lemmatized_tokens = segmented_text.split()  # Remplacer par la lemmatisation si nécessaire\n",
        "        else:\n",
        "            stemmed_tokens = tokens\n",
        "            lemmatized_tokens = tokens\n",
        "\n",
        "        processed_rows.append({\n",
        "            'Lyrics_Stemmed': stemmed_tokens,\n",
        "            'Lyrics_Lemmatized': lemmatized_tokens\n",
        "        })\n",
        "\n",
        "    processed_df_batch = pd.DataFrame(processed_rows)\n",
        "    processed_dfs.append(processed_df_batch)\n",
        "\n",
        "# Concaténer les DataFrames traités en lots\n",
        "final_processed_df = pd.concat(processed_dfs, ignore_index=True)\n",
        "\n",
        "# Sauvegarder les résultats dans un nouveau fichier CSV\n",
        "final_processed_df.to_csv('resultats_pretraites.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNBuF6p9CEav",
        "outputId": "aed36bf1-819e-4a95-e97f-e03f37e6164f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'farasa-api.qcri.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 241M/241M [02:07<00:00, 1.89MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-12-20 21:04:55,711 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:00,204 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:06,127 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:10,726 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:15,498 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:21,265 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:25,827 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:31,127 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:36,074 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:42,321 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:48,610 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:52,998 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:05:58,240 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:03,656 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:08,326 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:14,319 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:19,164 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:24,017 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:30,468 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:35,131 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:40,035 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:46,146 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:50,889 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:06:56,606 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:07:02,128 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:07:17,524 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from langdetect import detect\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from snowballstemmer import stemmer\n",
        "\n",
        "# Chargement du modèle spaCy pour l'anglais\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv('songs.csv')\n",
        "\n",
        "processed_rows_en = []\n",
        "for index, row in df.iterrows():\n",
        "    text = row['Lyrics']\n",
        "    if text and len(text.strip()) > 10:\n",
        "        lang = detect(text)\n",
        "        if lang == 'en':\n",
        "            # Tokenisation\n",
        "            tokenizer = RegexpTokenizer(r'\\w+')\n",
        "            tokens = tokenizer.tokenize(text)\n",
        "            tokens = [token.lower() for token in tokens if not token.isdigit()]\n",
        "            stop_words_english = set(stopwords.words('english'))\n",
        "            tokens = [token for token in tokens if token not in stop_words_english]\n",
        "\n",
        "            # Lemmatisation avec spaCy\n",
        "            doc = nlp(\" \".join(tokens))\n",
        "            lemmatized_tokens = [token.lemma_ for token in doc]\n",
        "\n",
        "            # Stemming (Snowball Stemmer)\n",
        "            stemmer_english = stemmer(\"english\")\n",
        "            stemmed_tokens = stemmer_english.stemWords(lemmatized_tokens)\n",
        "\n",
        "            processed_rows_en.append({\n",
        "                'Lyrics': stemmed_tokens\n",
        "            })\n",
        "\n",
        "# Création d'un DataFrame à partir des données prétraitées pour l'anglais\n",
        "final_processed_df_en = pd.DataFrame(processed_rows_en)\n",
        "final_processed_df_en.to_csv('resultats_pretraites_en.csv', index=False)\n"
      ],
      "metadata": {
        "id": "9KGgkISYDdiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langdetect import detect\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from snowballstemmer import stemmer\n",
        "\n",
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv('songs.csv')\n",
        "\n",
        "processed_rows_fr = []\n",
        "for index, row in df.iterrows():\n",
        "    text = row['Lyrics']\n",
        "    # Vérification de la longueur du texte\n",
        "    if text and len(text.strip()) > 10:  # Vérifie si le texte a plus de 10 caractères non blancs\n",
        "        lang = detect(text)\n",
        "\n",
        "        if lang == 'fr':\n",
        "            # Tokenisation\n",
        "            tokenizer = RegexpTokenizer(r'\\w+')\n",
        "            tokens = tokenizer.tokenize(text)\n",
        "\n",
        "            # Minuscules\n",
        "            tokens = [token.lower() for token in tokens]\n",
        "\n",
        "            # Suppression des chiffres\n",
        "            tokens = [token for token in tokens if not token.isdigit()]\n",
        "\n",
        "            # Suppression des mots vides (stop words)\n",
        "            stop_words_french = set(stopwords.words('french'))\n",
        "            tokens = [token for token in tokens if token not in stop_words_french]\n",
        "\n",
        "            # Stemming pour le français\n",
        "            stemmer_french = stemmer(\"french\")\n",
        "            stemmed_tokens = stemmer_french.stemWords(tokens)\n",
        "\n",
        "            processed_rows_fr.append({\n",
        "                'Lyrics_Stemmed': stemmed_tokens\n",
        "                # Ajoutez ici la lemmatisation si nécessaire\n",
        "            })\n",
        "\n",
        "# Création d'un DataFrame à partir des données prétraitées pour le français\n",
        "final_processed_df_fr = pd.DataFrame(processed_rows_fr)\n",
        "final_processed_df_fr.to_csv('resultats_pretraites_fr.csv', index=False)\n"
      ],
      "metadata": {
        "id": "miAPWeJ6FcQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from farasa.segmenter import FarasaSegmenter\n",
        "from snowballstemmer import stemmer\n",
        "from langdetect import detect\n",
        "import pandas as pd\n",
        "\n",
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv('songs.csv')\n",
        "\n",
        "processed_rows_ar = []\n",
        "for index, row in df.iterrows():\n",
        "    text = row['Lyrics']\n",
        "    # Vérification de la longueur du texte\n",
        "    if text and len(text.strip()) > 10:  # Vérifie si le texte a plus de 10 caractères non blancs\n",
        "        lang = detect(text)\n",
        "\n",
        "        if lang == 'ar':\n",
        "            # Initialisation du segmenteur Farasa\n",
        "            segmenter = FarasaSegmenter(interactive=True)\n",
        "\n",
        "            # Segmentation du texte en arabe\n",
        "            segmented_text = segmenter.segment(text)\n",
        "            tokens = segmented_text.split()  # Séparation des mots segmentés\n",
        "\n",
        "            # Suppression des chiffres\n",
        "            tokens = [token for token in tokens if not token.isdigit()]\n",
        "            # Stemming pour l'arabe\n",
        "            stemmer_arabic = stemmer(\"arabic\")\n",
        "            stemmed_tokens = stemmer_arabic.stemWords(tokens)\n",
        "\n",
        "            processed_rows_ar.append({\n",
        "                'Lyrics_Stemmed': stemmed_tokens\n",
        "                # Ajoutez ici la lemmatisation si nécessaire\n",
        "            })\n",
        "\n",
        "# Création d'un DataFrame à partir des données prétraitées pour l'arabe\n",
        "final_processed_df_ar = pd.DataFrame(processed_rows_ar)\n",
        "final_processed_df_ar.to_csv('resultats_pretraites_ar.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_B5_TsxIbZc",
        "outputId": "5bcc607f-d318-4f91-ae24-29a85f7fcdbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-12-20 21:30:13,339 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:30:19,090 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:30:23,639 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:30:28,371 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:30:34,421 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:30:38,996 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:30:44,275 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:30:49,756 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:30:54,206 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:00,155 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:04,770 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:09,423 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:15,835 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:21,553 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:28,700 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:33,303 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:37,867 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:44,334 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:49,193 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:31:54,160 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:32:00,081 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:32:04,868 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:32:11,040 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:32:16,165 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2023-12-20 21:32:26,587 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger les données depuis le fichier CSV\n",
        "data = pd.read_csv('data_cleaned.csv')\n"
      ],
      "metadata": {
        "id": "1f6FHjnYG0DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sélectionner la colonne contenant les paroles nettoyées\n",
        "lyrics_cleaned = data['Lyrics_cleaned']\n",
        "\n",
        "# Créer un objet Tokenizer et ajuster-le sur les paroles nettoyées\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lyrics_cleaned)\n",
        "\n",
        "# Convertir les paroles nettoyées en séquences numériques\n",
        "sequences = tokenizer.texts_to_sequences(lyrics_cleaned)\n",
        "\n",
        "# Déterminer la longueur maximale des séquences\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "\n",
        "# Remplir les séquences pour qu'elles aient toutes la même longueur\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "vF74PcHAG4zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense\n",
        "\n",
        "# Créer le modèle LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
        "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=len(tokenizer.word_index) + 1, activation='softmax'))\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Afficher un résumé du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thj-ITuWHyYP",
        "outputId": "6e9d7cb0-d1f2-4605-b833-a030d83bdaeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1296, 100)         3932600   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               117248    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 39326)             5073054   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9122902 (34.80 MB)\n",
            "Trainable params: 9122902 (34.80 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Charger les données depuis le fichier CSV\n",
        "data = pd.read_csv('data_cleaned.csv')\n",
        "\n",
        "# Sélectionner la colonne 'Lyrics_cleaned' comme texte pour le modèle\n",
        "lyrics_cleaned = data['Lyrics_cleaned']\n",
        "\n",
        "# Sélectionner la colonne 'Dialect' comme variable cible (labels)\n",
        "labels = data['Dialect']\n",
        "\n",
        "# Encodage des labels de dialecte en entiers\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Créer un objet Tokenizer et ajuster-le sur les paroles nettoyées\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lyrics_cleaned)\n",
        "sequences = tokenizer.texts_to_sequences(lyrics_cleaned)\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Créer le modèle LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
        "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=len(set(labels_encoded)), activation='softmax'))\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Évaluer le modèle sur l'ensemble de test\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oycr7kE1ICu6",
        "outputId": "c3c6d790-0267-4ef0-d48b-c6a9917a4163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.8936 - accuracy: 0.5636 - val_loss: 0.6999 - val_accuracy: 0.5625\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 58s 4s/step - loss: 0.4955 - accuracy: 0.8493 - val_loss: 0.4208 - val_accuracy: 0.8359\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 57s 4s/step - loss: 0.2911 - accuracy: 0.9335 - val_loss: 0.3167 - val_accuracy: 0.7891\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 60s 4s/step - loss: 0.1916 - accuracy: 0.9100 - val_loss: 0.2725 - val_accuracy: 0.8203\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 57s 4s/step - loss: 0.0695 - accuracy: 0.9863 - val_loss: 0.2642 - val_accuracy: 0.8594\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 56s 4s/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9141\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 57s 4s/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.1996 - val_accuracy: 0.9219\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 57s 4s/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9141\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 57s 4s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.8828\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 56s 4s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.8750\n",
            "4/4 [==============================] - 2s 371ms/step - loss: 0.4662 - accuracy: 0.8750\n",
            "Loss: 0.46617984771728516, Accuracy: 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOHixNZ1YGHD",
        "outputId": "ea813ee9-929c-4772-a6a5-0569a16ce353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv5_JaC-YJPk",
        "outputId": "2bee6ed2-f301-4875-ebcb-327271bf2a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier CSV prétraité\n",
        "data = pd.read_csv('data_cleaned.csv')\n",
        "# Diviser chaque texte en une liste de mots\n",
        "corpus = [text.split() for text in data]\n",
        "# Entraînement du modèle Word2Vec sur l'ensemble des mots uniques\n",
        "model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
        "# Enregistrer les vecteurs de mots dans un fichier texte\n",
        "with open('word_vectors.txt', 'w', encoding='utf-8') as file:\n",
        "    for word in model.wv.index_to_key:\n",
        "        vector = ' '.join(str(val) for val in model.wv[word])\n",
        "        file.write(f\"{word} {vector}\\n\")\n"
      ],
      "metadata": {
        "id": "DfcVgF8dQ-BC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}